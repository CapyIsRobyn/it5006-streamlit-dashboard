{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chicago Crime Data Preprocessing\n",
        "\n",
        "This notebook performs data cleaning and preprocessing on raw Chicago crime data.\n",
        "\n",
        "**Purpose:** \n",
        "- Remove redundant columns\n",
        "- Convert date formats\n",
        "- Handle missing values\n",
        "- Save cleaned data for analysis\n",
        "\n",
        "**Input Files:**\n",
        "- Training data: `chicago_crimes_2015_2024_raw.csv`\n",
        "- Test data: `chicago_crimes_2025_raw.csv`\n",
        "\n",
        "**Output Files:**\n",
        "- Training data: `chicago_crimes_2015_2024_cleaned.csv`\n",
        "- Test data: `chicago_crimes_2025_cleaned.csv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.DataFrame'>\n",
            "RangeIndex: 2519504 entries, 0 to 2519503\n",
            "Data columns (total 22 columns):\n",
            " #   Column                Dtype  \n",
            "---  ------                -----  \n",
            " 0   id                    int64  \n",
            " 1   case_number           str    \n",
            " 2   date                  str    \n",
            " 3   block                 str    \n",
            " 4   iucr                  str    \n",
            " 5   primary_type          str    \n",
            " 6   description           str    \n",
            " 7   location_description  str    \n",
            " 8   arrest                bool   \n",
            " 9   domestic              bool   \n",
            " 10  beat                  int64  \n",
            " 11  district              float64\n",
            " 12  ward                  float64\n",
            " 13  community_area        float64\n",
            " 14  fbi_code              str    \n",
            " 15  year                  int64  \n",
            " 16  updated_on            str    \n",
            " 17  x_coordinate          float64\n",
            " 18  y_coordinate          float64\n",
            " 19  latitude              float64\n",
            " 20  longitude             float64\n",
            " 21  location              str    \n",
            "dtypes: bool(2), float64(7), int64(3), str(10)\n",
            "memory usage: 389.3 MB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "id                          0\n",
              "case_number                 0\n",
              "date                        0\n",
              "block                       0\n",
              "iucr                        0\n",
              "primary_type                0\n",
              "description                 0\n",
              "location_description    12591\n",
              "arrest                      0\n",
              "domestic                    0\n",
              "beat                        0\n",
              "district                    1\n",
              "ward                       55\n",
              "community_area            176\n",
              "fbi_code                    0\n",
              "year                        0\n",
              "updated_on                  0\n",
              "x_coordinate            42228\n",
              "y_coordinate            42228\n",
              "latitude                42228\n",
              "longitude               42228\n",
              "location                42228\n",
              "dtype: int64"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Configuration\n",
        "RAW_DATA_PATH = \"../data/raw/\"\n",
        "PROCESSED_DATA_PATH = \"../data/processed/\"\n",
        "\n",
        "# Columns to remove from the raw dataset\n",
        "COLS_TO_DROP = [\n",
        "    'id', 'case_number', 'block', 'iucr', 'fbi_code', \n",
        "    'x_coordinate', 'y_coordinate', 'location', 'updated_on'\n",
        "]\n",
        "\n",
        "# data overview\n",
        "df = pd.read_csv(os.path.join(RAW_DATA_PATH, \"chicago_crimes_2015_2024_raw.csv\"))\n",
        "df.head()\n",
        "df.info()\n",
        "df.describe()\n",
        "df.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Preprocessing Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_crime_data(input_filename: str, output_filename: str):\n",
        "    \"\"\"\n",
        "    Load raw CSV, drop redundant columns, and perform basic cleaning.\n",
        "\n",
        "    Args:\n",
        "        input_filename: Name of the input file in RAW_DATA_PATH\n",
        "        output_filename: Name of the output file in PROCESSED_DATA_PATH\n",
        "    \"\"\"\n",
        "    input_path = os.path.join(RAW_DATA_PATH, input_filename)\n",
        "    output_path = os.path.join(PROCESSED_DATA_PATH, output_filename)\n",
        "\n",
        "    if not os.path.exists(input_path):\n",
        "        print(f\"Error: {input_path} not found!\")\n",
        "        return\n",
        "\n",
        "    print(f\"Loading data from {input_filename}...\")\n",
        "    df = pd.read_csv(input_path)\n",
        "    \n",
        "    # 1. Drop redundant columns\n",
        "    # errors='ignore' ensures the code does not fail if some columns are already missing\n",
        "    df.drop(columns=COLS_TO_DROP, inplace=True, errors='ignore')\n",
        "    print(f\"Dropped redundant columns: {COLS_TO_DROP}\")\n",
        "\n",
        "    # 2. Handle date format (recommended to do this in preprocessing)\n",
        "    # Convert string to real datetime objects for later feature extraction (weekday, hour, etc.)\n",
        "    if 'date' in df.columns:\n",
        "        print(\"Converting 'date' column to datetime objects...\")\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "    # 3. Handle missing values (optional but recommended)\n",
        "    # For example, rows with missing latitude/longitude usually cannot be used for spatial analysis\n",
        "    initial_len = len(df)\n",
        "    df.dropna(subset=['latitude', 'longitude', 'district'], inplace=True)\n",
        "    print(f\"Removed {initial_len - len(df)} rows with missing critical values.\")\n",
        "\n",
        "    # 4. Save cleaned data\n",
        "    os.makedirs(PROCESSED_DATA_PATH, exist_ok=True)\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"Successfully saved cleaned data to: {output_path}\")\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Preprocessing Execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Preprocess Training Data (2015â€“2024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting data preprocessing...\n",
            "Loading data from chicago_crimes_2015_2024_raw.csv...\n",
            "Dropped redundant columns: ['id', 'case_number', 'block', 'iucr', 'fbi_code', 'x_coordinate', 'y_coordinate', 'location', 'updated_on']\n",
            "Converting 'date' column to datetime objects...\n",
            "Removed 42229 rows with missing critical values.\n",
            "Successfully saved cleaned data to: ../data/processed/chicago_crimes_2015_2024_cleaned.csv\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting data preprocessing...\")\n",
        "\n",
        "preprocess_crime_data(\n",
        "    \"chicago_crimes_2015_2024_raw.csv\", \n",
        "    \"chicago_crimes_2015_2024_cleaned.csv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Preprocess Test Data (2025)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from chicago_crimes_2025_raw.csv...\n",
            "Dropped redundant columns: ['id', 'case_number', 'block', 'iucr', 'fbi_code', 'x_coordinate', 'y_coordinate', 'location', 'updated_on']\n",
            "Converting 'date' column to datetime objects...\n",
            "Removed 64 rows with missing critical values.\n",
            "Successfully saved cleaned data to: ../data/processed/chicago_crimes_2025_cleaned.csv\n",
            "------------------------------\n",
            "Preprocessing completed!\n"
          ]
        }
      ],
      "source": [
        "preprocess_crime_data(\n",
        "    \"chicago_crimes_2025_raw.csv\", \n",
        "    \"chicago_crimes_2025_cleaned.csv\"\n",
        ")\n",
        "\n",
        "print(\"Preprocessing completed!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
